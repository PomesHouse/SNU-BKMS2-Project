{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc261cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import SlackDirectoryLoader, JSONLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever, ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "# import lark\n",
    "#splitter\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed3d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jq\n",
      "  Downloading jq-1.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Downloading jq-1.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (663 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 kB\u001b[0m \u001b[31m890.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m905.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jq\n",
      "Successfully installed jq-1.6.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2d98c1-f637-4739-8276-35e70c7d0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98896785-826b-4f51-a786-4c89910e3e4c",
   "metadata": {},
   "source": [
    "### json loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c62173e8-e74b-4281-be33-8adfd1640d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_msg_id': 'da3133d0-7d09-4566-acb4-ed94313d4673', 'type': 'message', 'user': 'U01PVETHKF1', 'text': '오늘 혹시해서 팀즈에 들어가봤는데 팀즈에만 있는 공지물들이 있는데 혹시 앞으로 슬랙과 팀즈 둘다 확인해야 하는 건가요 ??', 'ts': '1615779072.014600', 'team': 'T01QA5S537V', 'reactions': [{'name': 'eyes', 'count': 2, 'users': ['U01QNSM488Z', 'U01Q3EP0E14']}], 'replace_original': False, 'delete_original': False, 'metadata': {'event_type': '', 'event_payload': None}, 'blocks': [{'type': 'rich_text', 'block_id': 'MKl', 'elements': [{'type': 'rich_text_section', 'elements': [{'type': 'text', 'text': '오늘 혹시해서 팀즈에 들어가봤는데 팀즈에만 있는 공지물들이 있는데 혹시 앞으로 슬랙과 팀즈 둘다 확인해야 하는 건가요 ??'}]}]}], 'user_team': 'T01QA5S537V', 'source_team': 'T01QA5S537V', 'user_profile': {'avatar_hash': '', 'image_72': 'https://secure.gravatar.com/avatar/be84ebc6ca5da495140ae8afe5d15b50.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png', 'first_name': 'CheHyun', 'real_name': 'CheHyun Lee', 'display_name': '1기_이채현', 'team': 'T01QA5S537V', 'name': 'saga1214', 'is_restricted': False, 'is_ultra_restricted': False}, 'reply_users_count': 0, 'reply_users': None}\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./json_files/random/2021-03-15.json\"\n",
    "data = json.loads(Path(file_path).read_text())\n",
    "\n",
    "print(data['array'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1f5d7d0-b8f1-4edc-aa1e-e1bf4b240237",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema='.array[].text',\n",
    "    text_content=False)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dab6108f-4578-4948-a47e-e9608af3191b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)\n",
    "# os.listdir('./json_files/students 2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "270465d6-4cd5-4c6e-b61f-d8d599bb2a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_base_dir = './json_files'\n",
    "\n",
    "for dir in os.listdir(json_base_dir):\n",
    "    json_dir = json_base_dir + '/' + dir\n",
    "    \n",
    "    for json_file_dir in os.listdir(json_dir):\n",
    "        json_file = json_dir + '/' + json_file_dir\n",
    "        if os.path.isdir(json_file):\n",
    "            continue\n",
    "        data = json.loads(Path(json_file).read_text())\n",
    "        json_data = {\"array\" : data}\n",
    "        \n",
    "        with open(json_file, 'w', encoding='utf-8') as wf:\n",
    "            json.dump(json_data, wf, indent=\"\\t\", ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c96959c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 342.77it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 331.26it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "DRIVE_FOLDER = \"./json_files/students 2023-1\"\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "    # if record.get(\"user_profile\"):\n",
    "    if record.get(\"user_profile\"):\n",
    "        metadata[\"sender_name\"] = record.get(\"user_profile\")#.get(\"display_name\")\n",
    "\n",
    "    if \"source\" in metadata:\n",
    "        source = metadata[\"source\"].split(\"/\")\n",
    "        metadata[\"date\"] = source[-1].split('.')[0]\n",
    "        metadata[\"source\"] = source[-2]\n",
    "        \n",
    "    return metadata\n",
    "\n",
    "\n",
    "# loader = JSONLoader(\n",
    "#     file_path='./example_data/facebook_chat.json',\n",
    "#     jq_schema='.messages[]',\n",
    "#     content_key=\"content\",\n",
    "#     metadata_func=metadata_func\n",
    "# )\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    DRIVE_FOLDER, \n",
    "    glob='**/*.json', \n",
    "    show_progress=True, \n",
    "    loader_cls=JSONLoader, \n",
    "    loader_kwargs = {'jq_schema': '.array[] | {text: .text, user_profile: .user_profile.display_name}', 'text_content':False, 'metadata_func':metadata_func},\n",
    "    # loader_kwargs = {'jq_schema': 'map({text_content : .text, real_name : .user_profile.display_name})'}\n",
    ")\n",
    "\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6d360-2a20-4e04-b9be-0313d4f60390",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[33].page_content\n",
    "print(docs[33])\n",
    "# text_dic = eval(doc)\n",
    "# print(text_dic)\n",
    "# text_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957ae8bf-f990-4cd8-8bbb-6b4829acba89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m docs_lis \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdocs\u001b[49m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text_dic \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28meval\u001b[39m(doc\u001b[38;5;241m.\u001b[39mpage_content)):\n\u001b[1;32m      4\u001b[0m         text \u001b[38;5;241m=\u001b[39m text_dic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "docs_lis = []\n",
    "for i, doc in enumerate(docs):\n",
    "    for text_dic in list(eval(doc.page_content)):\n",
    "        text = text_dic['text']\n",
    "        if isinstance(text, str):\n",
    "            # content = preprocess_text(text)\n",
    "            content = doc\n",
    "            doc.page_content = content\n",
    "            break      \n",
    "docs_lis += docs\n",
    "    # print(i, len(docs_lis))\n",
    "# docs = docs_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1d51a7cd-de95-42d1-9f8a-8d886befa3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'general 1'"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = docs[0].metadata['source']\n",
    "src.split('/')[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6fe9d-0840-4eb2-a855-a5837c1e8e84",
   "metadata": {},
   "source": [
    "### text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "5245a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8302eee1-466c-4eea-b242-70b843b5746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "# store = InMemoryStore()\n",
    "# retriever = ParentDocumentRetriever(\n",
    "#     vectorstore=db,\n",
    "#     docstore=store,\n",
    "#     child_splitter=child_splitter,\n",
    "# )\n",
    "\n",
    "# retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de68e83-1b51-4bf6-ae33-ac3f537d13e8",
   "metadata": {},
   "source": [
    "### Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd7ead36-efaa-4ca1-a18c-0139f073b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/92 [15:47<23:56:27, 947.11s/it]\n",
      "  1%|          | 1/92 [14:03<21:18:49, 843.18s/it]\n",
      "  1%|          | 1/92 [11:30<17:27:36, 690.73s/it]\n",
      "  1%|          | 1/92 [05:17<8:01:03, 317.18s/it]\n",
      "  1%|          | 1/92 [04:40<7:06:10, 280.99s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-ada-002' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97c88ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 35/92 [20:34<33:29, 35.26s/it] \n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-4uk80***************************************GeXR. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# db = Chroma.from_documents(\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     documents = docs, # 어느 docs를 사용할 것인가?\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     embedding = embedding,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     persist_directory = persist_directory\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/langchain_core/vectorstores.py:510\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    509\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/langchain/vectorstores/faiss.py:911\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    892\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m    893\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m    913\u001b[0m         texts,\n\u001b[1;32m    914\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    919\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/langchain/embeddings/openai.py:669\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/langchain/embeddings/openai.py:495\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    493\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 495\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    501\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/langchain/embeddings/openai.py:117\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_openai_v1():\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/openai/resources/embeddings.py:105\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     99\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    100\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/openai/_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1051\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1059\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1060\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1061\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1062\u001b[0m     )\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/openai/_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    841\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/openai/_base_client.py:885\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    884\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-4uk80***************************************GeXR. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "# db = Chroma.from_documents(\n",
    "#     documents = docs, # 어느 docs를 사용할 것인가?\n",
    "#     embedding = embedding,\n",
    "#     persist_directory = persist_directory\n",
    "# )\n",
    "\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfe979-4e3b-4537-bfe5-03d798a6d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25_retriever = BM25Retriever.from_texts(docs)\n",
    "# bm25_retriever.k = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee69b5fd-f033-4dfc-b8ba-1da224f37c3b",
   "metadata": {},
   "source": [
    "### ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6b95bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question and answering\n",
    "chatbot_chain = RetrievalQA.from_chain_type(\n",
    "    llm = ChatOpenAI(\n",
    "        temperature = 0.5, model_name = 'gpt-3.5-turbo', max_tokens = 500\n",
    "    ),\n",
    "    chain_type = \"stuff\", ## 뭐지?\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\" : 2}) ## search_kwargs 뭐하는 거지?\n",
    "    # retriever = retriever\n",
    ")\n",
    "\n",
    "# chatbot_chain = RetrievalQA.from_chain_type(\n",
    "# \t\tllm = ChatOpenAI(\n",
    "#         temperature = 0.5, model_name = 'gpt-3.5-turbo', max_tokens = 500\n",
    "#         ),\n",
    "# \t\tretriever = db.as_retriever(search_kwargs={\"k\" : 2}),\n",
    "# \t\tverbose=True, \n",
    "# \t\tchain_type_kwargs={\n",
    "# \t\t        'document_prompt': PromptTemplate(\n",
    "# \t\t            input_variables=[\"page_content\", \"sender_name\", \"source\", \"Date\"], \n",
    "# \t\t            template=\"Context:\\n{page_content}\\nSender:{sender_name}\\nSource:{source}\\nDate:{date}\"\n",
    "# \t\t        ),\n",
    "# \t\t    },\n",
    "# \t\t)\n",
    "\n",
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# chatbot_chain = ConversationalRetrievalChain.from_llm(ChatOpenAI(\n",
    "#         temperature = 0.7, model_name = 'gpt-3.5-turbo', max_tokens = 1000\n",
    "#     ), db.as_retriever(search_kwargs={\"k\" : 2}), return_source_documents=True)\n",
    "\n",
    "#chain type : stuff, map_reduce, refine\n",
    "# template = \"\"\"\n",
    "# {query}? page_content에서 필요한 내용이 있는지 확인하세요.\n",
    "# metadata에서 source의 정보를 확인하여 질문에 대한 답을 얻을 수 있을지 확인하세요.\n",
    "# 알고 있는 정보가 없다면 다른 단어는 포함하지 말고 해당 정보에 대한 내용이 없다고만 대답하세요.\n",
    "# \"\"\"\n",
    "template = \"\"\"\n",
    "{query}? Check page_content of Document whether it contains reliable contents.\n",
    "You also have to check source from metadata whether it can help you answer.\n",
    "If you have no any information, just answer you don't have any related info.\n",
    "Answer in Korean.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template = template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "82776e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "제가 대학교 관련 공지사항에 대한 정보를 가지고 있지는 않습니다. 이 문서에 대한 내용을 확인하거나, 메타데이터에서 소스를 확인해야 할 것 같습니다. 죄송하지만, 제가 관련된 정보를 가지고 있지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "# print(chatbot_chain.run(prompt.format(query = \"대학교 관련 공지사항이 무엇이 있나요?\")))\n",
    "print(chatbot_chain.run(prompt.format(query = \"대학교 관련 공지사항이 무엇이 있나요?\")))\n",
    "\n",
    "# chat_history = []\n",
    "\n",
    "# query = \"대학 관련 공지사항이 무엇이 있나요?\"\n",
    "# result = chatbot_chain({\"question\": prompt.format(query=query), \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "06aa0e3d-ec30-4c9c-bb5a-23cc087137bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result['answer'])\n",
    "# print(result['source_documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e5780-e7c3-48a2-ac69-42ecf77a6f38",
   "metadata": {},
   "source": [
    "## generate FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32e38708-679f-4474-a1ea-7ab90a12bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    unallowed_char = ['&gt', '&lt', '\\t', '\\n', ';']\n",
    "    for char in unallowed_char:\n",
    "        text = text.replace(char, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e8e1072-88fa-4d76-a253-26d904e2ab6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['general 4',\n",
       " 'random',\n",
       " 'general 2',\n",
       " 'students 2022-2',\n",
       " 'general 5',\n",
       " 'resource',\n",
       " 'general 3',\n",
       " 'students 2022-1',\n",
       " 'students 2021',\n",
       " 'students 2023-2',\n",
       " 'gsds-cluster',\n",
       " 'students 2023-1',\n",
       " '인턴십등광고홍보게시글',\n",
       " 'general 1']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./json_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2349358c-d809-4642-b1ca-0f34408dbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_base_dir = './faiss_index'\n",
    "json_base_dir = './json_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42dff9da-291d-4284-b507-67138c8eb5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 37%|███▋      | 34/92 [00:00<00:00, 335.30it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 338.95it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 344.10it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 344.08it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 343.36it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 343.25it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 341.44it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 342.40it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 343.50it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 343.58it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 342.43it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 334.07it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 342.07it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 333.39it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 341.85it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 331.72it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 340.78it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 333.38it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 341.74it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 332.66it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 35%|███▍      | 32/92 [00:00<00:00, 318.36it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 325.10it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 342.84it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 334.54it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 37%|███▋      | 34/92 [00:00<00:00, 332.99it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 330.28it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 342.56it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 333.45it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 37%|███▋      | 34/92 [00:00<00:00, 334.30it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 335.04it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-ada-002')\n",
    "docs_lis = []\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "    if record.get(\"user_profile\"):\n",
    "        metadata[\"sender_name\"] = record.get(\"user_profile\")\n",
    "    else:\n",
    "        metadata[\"sender_name\"] = 'unknown_user'\n",
    "\n",
    "    if \"source\" in metadata:\n",
    "        source = metadata[\"source\"].split(\"/\")\n",
    "        metadata[\"date\"] = source[-1].split('.')[0]\n",
    "        metadata[\"source\"] = source[-2]\n",
    "        \n",
    "    return metadata\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    DRIVE_FOLDER, \n",
    "    glob='**/*.json', \n",
    "    show_progress=True, \n",
    "    loader_cls=JSONLoader, \n",
    "    loader_kwargs = {'jq_schema': '.array[] | {text: .text, user_profile: .user_profile.display_name}', 'text_content':False, 'metadata_func':metadata_func},\n",
    ")\n",
    "\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "\n",
    "for json_dir in os.listdir(json_base_dir):\n",
    "    file_dir = json_base_dir + '/' + json_dir\n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        DRIVE_FOLDER, \n",
    "        glob='**/*.json', \n",
    "        show_progress=True, \n",
    "        loader_cls=JSONLoader, \n",
    "        loader_kwargs = {'jq_schema': '.array[] | {text: .text, user_profile: .user_profile.display_name}',\n",
    "                         'text_content':False,\n",
    "                         'metadata_func':metadata_func},\n",
    "    )\n",
    "\n",
    "\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_page = doc.page_content\n",
    "        doc_page = doc_page.replace('null', 'None')\n",
    "        # print(doc_page, type(doc_page))\n",
    "        text_dic = eval(doc_page)\n",
    "        if isinstance(text_dic['text'], str):\n",
    "            doc.page_content = preprocess_text(text_dic['text'])\n",
    "        \n",
    "    docs_lis += docs\n",
    "\n",
    "db = FAISS.from_documents(docs_lis, embeddings)\n",
    "db.save_local(index_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9c04f92-72de-4eca-a086-66746af242f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3682"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5880ed66-2de9-46b0-9a94-e3843f4f8e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=':mega:*[3기 학생회 모집]*:mega:3기 여러분 안녕하세요!:raised_hands::skin-tone-2:2기 학생 부대표 황예진입니다~! :grin:2022년 정말 바쁘셨을텐데 무사히 한 해를 보내신 걸 축하드리고 고생하셨습니다!어느덧 2023년 새해가 왔네요~! 모두 소망하는 일 모두 이루시고 행복 가득한 한 해 되시길 바랍니다:pray:2023년 학교를 이끌어갈 *3기 학생회를 모집*하고자 합니다!:laughing:학생회 활동을 통해 보다 자주적이고 학생 친화적인 공간으로 학교가 변화해 가는 것을 보면서 뿌듯함을 느끼고, 남은 1년 동안 학교를 위해 힘써주실 3기 분들께서는 지금 바로 저 <@U04242N8M8W> 에게 DM으로 연락 주세요~!:muscle:또한 여러분을 대표할 학생회를 꾸리는 것인 만큼 많은 투표 미리 부탁 드립니다~!!!모집 일정 및 절차- 후보자 등록 기간 : 1/2(공지시점)~1/5(목)정오- 지원 방법: <@U04242N8M8W> 에게 학번과 이름을 적어서 DM으로 지원!!!- 모집 인원: 2명 (대표 1명, 부대표 1명)- 임기: 선출시점 ~ 1년- 선거 기간: 1/6(목) 정오 ~ 1/11(수)- 석.박.석박 통합 과정 무관' metadata={'source': 'students 2023-1', 'seq_num': 1, 'sender_name': '2기_황예진', 'date': '2023-01-02'}\n",
      "\n",
      "page_content='현재 416 혹은 418 자리의 의자가 없다고 합니다. 혹시 사용하고 계신분은 자리에 가져다 주시면 감사하겠습니다! :pray: ' metadata={'source': 'students 2023-1', 'seq_num': 1, 'sender_name': 'unknown_user', 'date': '2023-03-08'}\n"
     ]
    }
   ],
   "source": [
    "print(docs_lis[33])\n",
    "print()\n",
    "print(docs_lis[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc668315-46ed-4604-9c0e-31180069fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.load_local(index_base_dir, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee33bed-a4a0-4c8f-a6e4-4dc080c07650",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907913bc-bdd2-44ef-bf2d-c43d53c599a7",
   "metadata": {},
   "source": [
    "1. https://python.langchain.com/docs/integrations/vectorstores/faiss\n",
    "2. https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
