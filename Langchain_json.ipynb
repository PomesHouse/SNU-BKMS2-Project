{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc261cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import SlackDirectoryLoader, JSONLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever, ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "# import lark\n",
    "#splitter\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, TokenTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed3d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jq\n",
      "  Downloading jq-1.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Downloading jq-1.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (663 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 kB\u001b[0m \u001b[31m890.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m905.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jq\n",
      "Successfully installed jq-1.6.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2d98c1-f637-4739-8276-35e70c7d0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98896785-826b-4f51-a786-4c89910e3e4c",
   "metadata": {},
   "source": [
    "### json loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c62173e8-e74b-4281-be33-8adfd1640d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_msg_id': 'da3133d0-7d09-4566-acb4-ed94313d4673', 'type': 'message', 'user': 'U01PVETHKF1', 'text': '오늘 혹시해서 팀즈에 들어가봤는데 팀즈에만 있는 공지물들이 있는데 혹시 앞으로 슬랙과 팀즈 둘다 확인해야 하는 건가요 ??', 'ts': '1615779072.014600', 'team': 'T01QA5S537V', 'reactions': [{'name': 'eyes', 'count': 2, 'users': ['U01QNSM488Z', 'U01Q3EP0E14']}], 'replace_original': False, 'delete_original': False, 'metadata': {'event_type': '', 'event_payload': None}, 'blocks': [{'type': 'rich_text', 'block_id': 'MKl', 'elements': [{'type': 'rich_text_section', 'elements': [{'type': 'text', 'text': '오늘 혹시해서 팀즈에 들어가봤는데 팀즈에만 있는 공지물들이 있는데 혹시 앞으로 슬랙과 팀즈 둘다 확인해야 하는 건가요 ??'}]}]}], 'user_team': 'T01QA5S537V', 'source_team': 'T01QA5S537V', 'user_profile': {'avatar_hash': '', 'image_72': 'https://secure.gravatar.com/avatar/be84ebc6ca5da495140ae8afe5d15b50.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0001-72.png', 'first_name': 'CheHyun', 'real_name': 'CheHyun Lee', 'display_name': '1기_이채현', 'team': 'T01QA5S537V', 'name': 'saga1214', 'is_restricted': False, 'is_ultra_restricted': False}, 'reply_users_count': 0, 'reply_users': None}\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./json_files/random/2021-03-15.json\"\n",
    "data = json.loads(Path(file_path).read_text())\n",
    "\n",
    "print(data['array'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1f5d7d0-b8f1-4edc-aa1e-e1bf4b240237",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema='.array[].text',\n",
    "    text_content=False)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dab6108f-4578-4948-a47e-e9608af3191b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)\n",
    "# os.listdir('./json_files/students 2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "270465d6-4cd5-4c6e-b61f-d8d599bb2a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_base_dir = './json_files'\n",
    "\n",
    "for dir in os.listdir(json_base_dir):\n",
    "    json_dir = json_base_dir + '/' + dir\n",
    "    \n",
    "    for json_file_dir in os.listdir(json_dir):\n",
    "        json_file = json_dir + '/' + json_file_dir\n",
    "        if os.path.isdir(json_file):\n",
    "            continue\n",
    "        data = json.loads(Path(json_file).read_text())\n",
    "        json_data = {\"array\" : data}\n",
    "        \n",
    "        with open(json_file, 'w', encoding='utf-8') as wf:\n",
    "            json.dump(json_data, wf, indent=\"\\t\", ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c96959c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 38%|███▊      | 35/92 [00:00<00:00, 342.77it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 331.26it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "DRIVE_FOLDER = \"./json_files/students 2023-1\"\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "    # if record.get(\"user_profile\"):\n",
    "    if record.get(\"user_profile\"):\n",
    "        metadata[\"sender_name\"] = record.get(\"user_profile\")#.get(\"display_name\")\n",
    "\n",
    "    if \"source\" in metadata:\n",
    "        source = metadata[\"source\"].split(\"/\")\n",
    "        metadata[\"date\"] = source[-1].split('.')[0]\n",
    "        metadata[\"source\"] = source[-2]\n",
    "        \n",
    "    return metadata\n",
    "\n",
    "\n",
    "# loader = JSONLoader(\n",
    "#     file_path='./example_data/facebook_chat.json',\n",
    "#     jq_schema='.messages[]',\n",
    "#     content_key=\"content\",\n",
    "#     metadata_func=metadata_func\n",
    "# )\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    DRIVE_FOLDER, \n",
    "    glob='**/*.json', \n",
    "    show_progress=True, \n",
    "    loader_cls=JSONLoader, \n",
    "    loader_kwargs = {'jq_schema': '.array[] | {text: .text, user_profile: .user_profile.display_name}', 'text_content':False, 'metadata_func':metadata_func},\n",
    "    # loader_kwargs = {'jq_schema': 'map({text_content : .text, real_name : .user_profile.display_name})'}\n",
    ")\n",
    "\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6d360-2a20-4e04-b9be-0313d4f60390",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[33].page_content\n",
    "print(docs[33])\n",
    "# text_dic = eval(doc)\n",
    "# print(text_dic)\n",
    "# text_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957ae8bf-f990-4cd8-8bbb-6b4829acba89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m docs_lis \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdocs\u001b[49m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text_dic \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28meval\u001b[39m(doc\u001b[38;5;241m.\u001b[39mpage_content)):\n\u001b[1;32m      4\u001b[0m         text \u001b[38;5;241m=\u001b[39m text_dic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "docs_lis = []\n",
    "for i, doc in enumerate(docs):\n",
    "    for text_dic in list(eval(doc.page_content)):\n",
    "        text = text_dic['text']\n",
    "        if isinstance(text, str):\n",
    "            # content = preprocess_text(text)\n",
    "            content = doc\n",
    "            doc.page_content = content\n",
    "            break      \n",
    "docs_lis += docs\n",
    "    # print(i, len(docs_lis))\n",
    "# docs = docs_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1d51a7cd-de95-42d1-9f8a-8d886befa3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'general 1'"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = docs[0].metadata['source']\n",
    "src.split('/')[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6fe9d-0840-4eb2-a855-a5837c1e8e84",
   "metadata": {},
   "source": [
    "### text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "5245a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8302eee1-466c-4eea-b242-70b843b5746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "# store = InMemoryStore()\n",
    "# retriever = ParentDocumentRetriever(\n",
    "#     vectorstore=db,\n",
    "#     docstore=store,\n",
    "#     child_splitter=child_splitter,\n",
    "# )\n",
    "\n",
    "# retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de68e83-1b51-4bf6-ae33-ac3f537d13e8",
   "metadata": {},
   "source": [
    "### Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd7ead36-efaa-4ca1-a18c-0139f073b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/92 [15:47<23:56:27, 947.11s/it]\n",
      "  1%|          | 1/92 [14:03<21:18:49, 843.18s/it]\n",
      "  1%|          | 1/92 [11:30<17:27:36, 690.73s/it]\n",
      "  1%|          | 1/92 [05:17<8:01:03, 317.18s/it]\n",
      "  1%|          | 1/92 [04:40<7:06:10, 280.99s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-ada-002' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97c88ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/99 [36:19<59:19:27, 2179.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# db = Chroma.from_documents(\n",
    "#     documents = docs, # 어느 docs를 사용할 것인가?\n",
    "#     embedding = embedding,\n",
    "#     persist_directory = persist_directory\n",
    "# )\n",
    "\n",
    "db = FAISS.from_documents(docs_lis, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfe979-4e3b-4537-bfe5-03d798a6d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25_retriever = BM25Retriever.from_texts(docs)\n",
    "# bm25_retriever.k = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee69b5fd-f033-4dfc-b8ba-1da224f37c3b",
   "metadata": {},
   "source": [
    "### ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "711b2f39-b1bb-4c09-8314-41a3067318d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Self query retriever with Vector Store type <class 'langchain.vectorstores.faiss.FAISS'> not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m document_content_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent of the message\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mMyRetriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument_content_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_field_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_field_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/langchain/retrievers/self_query/base.py:208\u001b[0m, in \u001b[0;36mSelfQueryRetriever.from_llm\u001b[0;34m(cls, llm, vectorstore, document_contents, metadata_field_info, structured_query_translator, chain_kwargs, enable_limit, use_original_query, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_llm\u001b[39m(\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelfQueryRetriever\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m structured_query_translator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m         structured_query_translator \u001b[38;5;241m=\u001b[39m \u001b[43m_get_builtin_translator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     chain_kwargs \u001b[38;5;241m=\u001b[39m chain_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed_comparators\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m chain_kwargs\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m structured_query_translator\u001b[38;5;241m.\u001b[39mallowed_comparators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda/envs/bkms/lib/python3.8/site-packages/langchain/retrievers/self_query/base.py:82\u001b[0m, in \u001b[0;36m_get_builtin_translator\u001b[0;34m(vectorstore)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BUILTIN_TRANSLATORS[vectorstore\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m]()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelf query retriever with Vector Store type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvectorstore\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Self query retriever with Vector Store type <class 'langchain.vectorstores.faiss.FAISS'> not supported."
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "class MyRetriever(SelfQueryRetriever):\n",
    "    def _get_docs(\n",
    "        self,\n",
    "        question: str,\n",
    "        *,\n",
    "        run_manager,\n",
    "    ):\n",
    "        \"\"\"Get docs.\"\"\"\n",
    "        # Retrieve documents based on the content\n",
    "        docs_content = self.retriever.get_relevant_documents(\n",
    "            question, callbacks=run_manager.get_child()\n",
    "        )\n",
    "    \n",
    "        # Retrieve documents based on the metadata\n",
    "        docs_metadata = self.retriever.get_relevant_documents(\n",
    "            question, callbacks=run_manager.get_child(), consider_metadata=True\n",
    "        )\n",
    "    \n",
    "        # Combine the two lists of documents\n",
    "        docs = docs_content + docs_metadata\n",
    "    \n",
    "        return docs\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(name=\"sender_name\", description = \"the sender who send the message\", type=\"string\"),\n",
    "    AttributeInfo(name=\"date\", description = \"date when the message was sent\", type=\"datetime.date\"),\n",
    "    AttributeInfo(name=\"source\", description = \"name of the chat where the message was sent to\", type=\"string\"),   \n",
    "]\n",
    "document_content_description = \"Content of the message\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.5)\n",
    "retriever = MyRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore=db,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f6b95bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "# metadata_field_info = [\n",
    "#     AttributeInfo(\n",
    "#         name=\"source\",\n",
    "#         description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "#         type=\"string\",\n",
    "#     ),\n",
    "#     AttributeInfo(\n",
    "#         name=\"page\",\n",
    "#         description=\"The page from the lecture\",\n",
    "#         type=\"integer\",\n",
    "#     ),\n",
    "# ]\n",
    "\n",
    "#Question and answering\n",
    "# chatbot_chain = RetrievalQA.from_chain_type(\n",
    "#     llm = ChatOpenAI(\n",
    "#         temperature = 0.3, model_name = 'gpt-3.5-turbo', max_tokens = 500\n",
    "#     ),\n",
    "#     chain_type = \"stuff\", ## 뭐지?\n",
    "#     retriever = db.as_retriever(\n",
    "#         search_kwargs={\"k\" : 2},\n",
    "        \n",
    "#     )\n",
    "# )\n",
    "\n",
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# chatbot_chain = ConversationalRetrievalChain.from_llm(\n",
    "#     ChatOpenAI(\n",
    "#         temperature = 0.5, model_name = 'gpt-3.5-turbo', max_tokens = 1000\n",
    "#     ),\n",
    "#     db.as_retriever(search_kwargs={\"k\" : 2}),\n",
    "#     return_source_documents=True\n",
    "# )\n",
    "\n",
    "#chain type : stuff, map_reduce, refine\n",
    "\n",
    "# template = \"\"\"\n",
    "# {query}? Check page_content of Document whether it contains reliable contents.\n",
    "# You also have to check source from metadata whether it can help you answer.\n",
    "# If you have no any information, just answer you don't have any related info.\n",
    "# Answer in Korean.\n",
    "# \"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "{query} page_content에서 필요한 정보를 찾으세요.\n",
    "metadata 정보를 가지고 보낸 사람과 출처를 활용하세요. 해당 정보를 출력할 필요는 없습니다.\n",
    "관련 정보를 자세하게 알려주세요.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template = template,\n",
    ")\n",
    "\n",
    "chatbot_chain = RetrievalQA.from_chain_type(\n",
    "\t\tllm = ChatOpenAI(\n",
    "        temperature = 0.5, model_name = 'gpt-3.5-turbo', max_tokens = 2000\n",
    "        ),\n",
    "\t\tretriever = db.as_retriever(search_kwargs={\"k\" : 3}),\n",
    "\t\tverbose=True,\n",
    "        chain_type = \"stuff\",\n",
    "\t\tchain_type_kwargs={\n",
    "\t\t        'document_prompt': PromptTemplate(\n",
    "\t\t            input_variables=[\"page_content\", \"sender_name\", \"source\", \"Date\"], \n",
    "\t\t            template=\"내용:\\n{page_content}\\n보낸 사람:{sender_name}\\n출처:{source}\\n보낸 날짜:{date}\"\n",
    "\t\t        )\n",
    "\t\t    },\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "82776e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "1. 2021 지식재산 정보 활용 창업 경진대회\n",
      "   - 주최: 한국특허정보원\n",
      "   - 관련 메시지: GSDS행정실로부터 보낸 메시지\n",
      "   - 보낸 날짜: 2021-03-18\n",
      "   - 대회 내용: 지식재산 정보를 활용한 창업 아이디어를 제출하는 대회\n",
      "\n",
      "2. 해커톤 대회 - 자연어처리 기법을 활용한 매장 메뉴 정리\n",
      "   - 주최: 개인적으로 참가자를 모집하는 석사 3기 박성일\n",
      "   - 관련 메시지: 3기_박성일로부터 보낸 메시지\n",
      "   - 보낸 날짜: 2022-11-22\n",
      "   - 대회 내용: 자연어처리 기법을 사용하여 매장 메뉴를 정리하는 프로젝트에 참가하는 대회. 1~2명의 모집인원을 받고, 2박 3일 동안 진행되며 상금과 상품이 제공됨.\n",
      "\n",
      "3. 홈페이지 학생소개 게시사항 조사\n",
      "   - 주최: 2기_김진웅\n",
      "   - 관련 메시지: 2기_김진웅로부터 보낸 메시지\n",
      "   - 보낸 날짜: 2021-03-22\n",
      "   - 대회 내용: 홈페이지에 게시될 본인 소개 항목을 작성하는 대회. 기한은 2021년 3월 24일까지이며, 수정이 필요한 경우에도 작성해야 함.\n"
     ]
    }
   ],
   "source": [
    "# print(chatbot_chain.run(prompt.format(query = \"대학교 관련 공지사항이 무엇이 있나요?\")))\n",
    "result = chatbot_chain.run(prompt.format(query = \"석사가 참여할 수 있는 대회 공지 3개를 알려주세요.\"))\n",
    "print(result)\n",
    "# print(chatbot_chain.run({\"query\":\"알고 있는 것이 뭔가요?\"}))\n",
    "\n",
    "# chat_history = []\n",
    "\n",
    "# query = \"대학 관련 공지사항이 무엇이 있나요?\"\n",
    "# result = chatbot_chain({\"question\": prompt.format(query=query), \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06aa0e3d-ec30-4c9c-bb5a-23cc087137bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터사이언스대학원 교수실 및 행정실이 43동으로 이전하는 공지가 있었습니다. 이외에는 추가적인 대학 관련 공지사항에 대한 정보가 없습니다.\n",
      "[Document(page_content='*[데이터사이언스대학원 교수실 및 행정실 43동 이전에 대한 공지 전달]*안녕하세요,오늘 general  채널에 * 데이터사이언스대학원 교수실 및 행정실 43동 이전 안내 * 공지가 올라왔습니다.자세한 내용은 본 공지를 확인하여 주시고 혹시 이전에 대한 문의사항이 있다면 학생회를 통해 문의해주시기 바랍니다.감사합니다', metadata={'source': 'students 2023-2', 'seq_num': 2, 'sender_name': 'unknown_user', 'date': '2023-08-09'}), Document(page_content='<@U01QNJ7PWRX> 안녕하세요~ 혹시 교수님 면담, 랩실 지원, 배정 결과 공개 등과 관련된 6월 일정을 미리 공지해주실 수 있을까요? 여름방학 계획에 참조하고자 합니다!', metadata={'source': 'random', 'seq_num': 1, 'sender_name': '3기_김소정_94', 'date': '2022-05-18'})]\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])\n",
    "# print(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "42e2162f-3c15-4089-b83c-302cf4e66328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='한국특허정보원에서 주관하는 2021 지식재산 정보 활용 창업 경진대회 관련하여 포스터 게시 요청이 있어 아래와 같이 알려드리니 관심있는 학생분들께서는 확인하시기 바랍니다.', metadata={'source': 'general 1', 'seq_num': 1, 'sender_name': 'GSDS행정실', 'date': '2021-03-18'}), Document(page_content='국가정보원 2023 정기 공채 모집 공고공고문을 확인해주세요.', metadata={'source': '인턴십등광고홍보게시글', 'seq_num': 273, 'sender_name': 'GSDS행정실', 'date': '2023-05-01'}), Document(page_content='상세사항은 기존 논문심사 계획 공지사항 Proposal 의 내용을 참고해주십시오. A4용지 자유양식으로 10매 이내입니다.', metadata={'source': 'general 4', 'seq_num': 2, 'sender_name': 'GSDS행정실', 'date': '2023-04-20'}), Document(page_content='[홈페이지 학생소개 게시사항 조사]아래 링크를 통해 홈페이지에 게시될 본인 소개항목을 작성해주세요.누구나 수정권한이 있기 때문에 링크 주소 대외보안 부탁드립니다.기한: 03.24일(수요일)(1기) 기존에 올라간 내용을 업데이트하고 싶으신 경우 5가지 항목 전부 작성해주세요.(2기) 기작성된 항목에 대해서도 수정이 필요한지 반드시 확인해주세요.<https://docs.google.com/spreadsheets/d/1Oe39IR2cda5fZroCVR6quBXBKXiEcEUUmN0EhUrk7kY/edit?usp=sharing>감사합니다.', metadata={'source': 'students 2021', 'seq_num': 2, 'sender_name': '2기_김진웅', 'date': '2021-03-22'})]\n"
     ]
    }
   ],
   "source": [
    "query = \"대회 관련 공지사항이 무엇이 있나요? page_content에서 필요한 정보를 찾으세요.\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e5780-e7c3-48a2-ac69-42ecf77a6f38",
   "metadata": {},
   "source": [
    "## generate FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e38708-679f-4474-a1ea-7ab90a12bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    unallowed_char = ['&gt', '&lt', '\\t', '\\n', ';']\n",
    "    for char in unallowed_char:\n",
    "        text = text.replace(char, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8e1072-88fa-4d76-a253-26d904e2ab6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['general 4',\n",
       " 'random',\n",
       " 'general 2',\n",
       " 'students 2022-2',\n",
       " 'general 5',\n",
       " 'resource',\n",
       " 'general 3',\n",
       " 'students 2022-1',\n",
       " 'students 2021',\n",
       " 'students 2023-2',\n",
       " 'gsds-cluster',\n",
       " 'students 2023-1',\n",
       " '인턴십등광고홍보게시글',\n",
       " 'general 1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./json_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2349358c-d809-4642-b1ca-0f34408dbb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_base_dir = './faiss_index'\n",
    "json_base_dir = './json_files_copy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42dff9da-291d-4284-b507-67138c8eb5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 5/99 [00:00<00:01, 49.44it/s]\u001b[A\n",
      " 10%|█         | 10/99 [00:00<00:01, 49.72it/s]\u001b[A\n",
      " 15%|█▌        | 15/99 [00:00<00:01, 48.65it/s]\u001b[A\n",
      " 21%|██        | 21/99 [00:00<00:01, 52.92it/s]\u001b[A\n",
      " 29%|██▉       | 29/99 [00:00<00:01, 61.15it/s]\u001b[A\n",
      " 36%|███▋      | 36/99 [00:00<00:01, 62.40it/s]\u001b[A\n",
      " 47%|████▋     | 47/99 [00:00<00:00, 72.88it/s]\u001b[A\n",
      " 56%|█████▌    | 55/99 [00:00<00:00, 73.63it/s]\u001b[A\n",
      " 64%|██████▎   | 63/99 [00:00<00:00, 73.69it/s]\u001b[A\n",
      " 74%|███████▎  | 73/99 [00:01<00:00, 80.98it/s]\u001b[A\n",
      " 84%|████████▍ | 83/99 [00:01<00:00, 85.74it/s]\u001b[A\n",
      "100%|██████████| 99/99 [00:01<00:00, 72.44it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      " 45%|████▌     | 15/33 [00:00<00:00, 148.68it/s]\u001b[A\n",
      "100%|██████████| 33/33 [00:00<00:00, 162.44it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:00<00:00, 94.12it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:00<00:00, 87.49it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:00<00:00, 104.38it/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:00<00:00, 104.05it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:00<00:00, 99.47it/s] \u001b[A\n",
      " 68%|██████▊   | 68/100 [00:00<00:00, 108.49it/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:00<00:00, 108.58it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 106.50it/s][A\n",
      "\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]\u001b[A\n",
      " 42%|████▏     | 13/31 [00:00<00:00, 113.20it/s]\u001b[A\n",
      "100%|██████████| 31/31 [00:00<00:00, 107.77it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/97 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▏        | 12/97 [00:00<00:00, 112.16it/s]\u001b[A\n",
      " 25%|██▍       | 24/97 [00:00<00:00, 111.99it/s]\u001b[A\n",
      " 37%|███▋      | 36/97 [00:00<00:00, 98.94it/s] \u001b[A\n",
      " 55%|█████▍    | 53/97 [00:00<00:00, 120.43it/s]\u001b[A\n",
      " 68%|██████▊   | 66/97 [00:00<00:00, 118.26it/s]\u001b[A\n",
      " 80%|████████  | 78/97 [00:00<00:00, 114.92it/s]\u001b[A\n",
      "100%|██████████| 97/97 [00:00<00:00, 117.47it/s]\u001b[A\n",
      "\n",
      "100%|██████████| 16/16 [00:00<00:00, 200.34it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:00<00:01, 71.38it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:00<00:01, 71.12it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:00<00:01, 70.04it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:00<00:01, 67.74it/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:00<00:00, 62.02it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:00<00:00, 72.31it/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:00<00:00, 82.56it/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:00<00:00, 79.52it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:01<00:00, 92.63it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 86.87it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▏        | 11/93 [00:00<00:00, 94.02it/s]\u001b[A\n",
      " 24%|██▎       | 22/93 [00:00<00:00, 96.23it/s]\u001b[A\n",
      " 38%|███▊      | 35/93 [00:00<00:00, 107.82it/s]\u001b[A\n",
      " 49%|████▉     | 46/93 [00:00<00:00, 94.03it/s] \u001b[A\n",
      " 62%|██████▏   | 58/93 [00:00<00:00, 100.25it/s]\u001b[A\n",
      " 75%|███████▌  | 70/93 [00:00<00:00, 103.10it/s]\u001b[A\n",
      "100%|██████████| 93/93 [00:00<00:00, 107.28it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 5/63 [00:00<00:01, 46.06it/s]\u001b[A\n",
      " 21%|██        | 13/63 [00:00<00:00, 60.56it/s]\u001b[A\n",
      " 40%|███▉      | 25/63 [00:00<00:00, 81.00it/s]\u001b[A\n",
      " 54%|█████▍    | 34/63 [00:00<00:00, 74.22it/s]\u001b[A\n",
      " 67%|██████▋   | 42/63 [00:00<00:00, 75.51it/s]\u001b[A\n",
      " 79%|███████▉  | 50/63 [00:00<00:00, 74.25it/s]\u001b[A\n",
      "100%|██████████| 63/63 [00:00<00:00, 74.85it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]\u001b[A\n",
      " 42%|████▏     | 20/48 [00:00<00:00, 199.73it/s]\u001b[A\n",
      "100%|██████████| 48/48 [00:00<00:00, 194.26it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 37/37 [00:00<00:00, 220.58it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/92 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|███       | 28/92 [00:00<00:00, 275.06it/s]\u001b[A\n",
      " 61%|██████    | 56/92 [00:00<00:00, 265.29it/s]\u001b[A\n",
      "100%|██████████| 92/92 [00:00<00:00, 266.90it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      " 31%|███       | 11/36 [00:00<00:00, 106.44it/s]\u001b[A\n",
      " 61%|██████    | 22/36 [00:00<00:00, 69.38it/s] \u001b[A\n",
      "100%|██████████| 36/36 [00:00<00:00, 58.16it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▏        | 12/99 [00:00<00:00, 113.58it/s]\u001b[A\n",
      " 36%|███▋      | 36/99 [00:00<00:00, 163.67it/s]\u001b[A\n",
      " 57%|█████▋    | 56/99 [00:00<00:00, 178.21it/s]\u001b[A\n",
      "100%|██████████| 99/99 [00:00<00:00, 189.76it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-ada-002')\n",
    "docs_lis = []\n",
    "\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "\n",
    "    if record.get(\"user_profile\"):\n",
    "        metadata[\"sender_name\"] = record.get(\"user_profile\")\n",
    "    else:\n",
    "        metadata[\"sender_name\"] = 'unknown_user'\n",
    "\n",
    "    if \"source\" in metadata:\n",
    "        source = metadata[\"source\"].split(\"/\")\n",
    "        metadata[\"date\"] = source[-1].split('.')[0]\n",
    "        metadata[\"source\"] = source[-2]\n",
    "        \n",
    "    return metadata\n",
    "\n",
    "# loader = DirectoryLoader(\n",
    "#     DRIVE_FOLDER, \n",
    "#     glob='**/*.json', \n",
    "#     show_progress=True, \n",
    "#     loader_cls=JSONLoader, \n",
    "#     loader_kwargs = {'jq_schema': '.array[] | {text: .text, user_profile: .user_profile.display_name}', 'text_content':False, 'metadata_func':metadata_func},\n",
    "# )\n",
    "\n",
    "\n",
    "# docs = loader.load()\n",
    "\n",
    "\n",
    "\n",
    "for json_dir in os.listdir(json_base_dir):\n",
    "    file_dir = json_base_dir + '/' + json_dir\n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        file_dir, \n",
    "        glob='**/*.json', \n",
    "        show_progress=True, \n",
    "        loader_cls=JSONLoader, \n",
    "        loader_kwargs = {'jq_schema': '.[] | {text: .text, user_profile: .user_profile.display_name}',\n",
    "                         'text_content':False,\n",
    "                         'metadata_func':metadata_func},\n",
    "    )\n",
    "\n",
    "\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_page = doc.page_content\n",
    "        doc_page = doc_page.replace('null', 'None')\n",
    "        # print(doc_page, type(doc_page))\n",
    "        text_dic = eval(doc_page)\n",
    "        if isinstance(text_dic['text'], str):\n",
    "            doc.page_content = preprocess_text(text_dic['text'])\n",
    "        \n",
    "    docs_lis += docs\n",
    "\n",
    "db = FAISS.from_documents(docs_lis, embeddings)\n",
    "db.save_local(index_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9c04f92-72de-4eca-a086-66746af242f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2547"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5880ed66-2de9-46b0-9a94-e3843f4f8e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='데이터사이언스대학원 신규 홈페이지 오픈 작업 안내 (4.21.(금))데이터사이언스대학원 신규 홈페이지 오픈을 위하여 다음과 같이 작업을 시행 중에 있습니다. 해당 시간 중 홈페이지 접속이 원활하지 않을 수 있으니 참고하시기 바랍니다.ㅇ 기간: 2023.4.21.(금) 09:00~16:00 (예정) ※ 추가 소요될 수 있음ㅇ 대상: 데이터사이언스대학원 홈페이지 <http://gsds.snu.ac.kr|gsds.snu.ac.kr>ㅇ 내용: 종전 홈페이지 종료 및 신규 홈페이지 오픈(배포)' metadata={'source': 'general 4', 'seq_num': 1, 'sender_name': 'GSDS행정실', 'date': '2023-04-21'}\n",
      "\n",
      "page_content='안녕하세요!해당 행사의 참석인원이 예상보다 많아져 삼성 모바일 사업부 측과 논의한 결과, 보다 원활한 행사 진행을 위해 두 타임에 걸쳐 진행하게 되었습니다.시간대별 참석인원이 정해져야 하기 때문에, 투표를 기준으로 참석 의사를 결정해야 할 것 같습니다. *따라서 행사에 참석을 원하시는 분들은 시간대 투표에 꼭 참석해주시기 바랍니다! (8/10일까지)*' metadata={'source': '인턴십등광고홍보게시글', 'seq_num': 3, 'sender_name': 'unknown_user', 'date': '2023-08-07'}\n"
     ]
    }
   ],
   "source": [
    "print(docs_lis[33])\n",
    "print()\n",
    "print(docs_lis[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc668315-46ed-4604-9c0e-31180069fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.load_local(index_base_dir, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee33bed-a4a0-4c8f-a6e4-4dc080c07650",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907913bc-bdd2-44ef-bf2d-c43d53c599a7",
   "metadata": {},
   "source": [
    "1. https://python.langchain.com/docs/integrations/vectorstores/faiss\n",
    "2. https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
